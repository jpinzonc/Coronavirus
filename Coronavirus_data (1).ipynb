{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re \n",
    "import imp\n",
    "from datetime import datetime\n",
    "from math import pi\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import googlemaps\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import seaborn\n",
    "from shapely.geometry import Point, Polygon\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook, show, output_file\n",
    "from bokeh.plotting import figure, gmap, output_file\n",
    "from bokeh.palettes import brewer, mpl\n",
    "from bokeh.models import GeoJSONDataSource,LinearColorMapper, ColorBar, Label, HoverTool, ColumnDataSource\n",
    "from bokeh.models import Range1d, ColorMapper, GMapOptions\n",
    "from bokeh.models.glyphs import MultiLine\n",
    "from bokeh.models.annotations import Title \n",
    "from bokeh.models.callbacks import CustomJS \n",
    "from bokeh.models.widgets.inputs import MultiSelect\n",
    "from bokeh.models.formatters import NumeralTickFormatter, DatetimeTickFormatter\n",
    "from bokeh.tile_providers import CARTODBPOSITRON, get_provider\n",
    "from bokeh.layouts import gridplot,row, column , grid\n",
    "sys.setrecursionlimit(40000)\n",
    "warnings.filterwarnings('ignore')\n",
    "# GOOGLE API KEY FOR MAP \n",
    "file_api = '../00_Credentials_files/app_keys.py'\n",
    "keys = imp.load_source('keys', file_api) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET NEW DATA\n",
    "### archived_daily_case_updates \n",
    "# def corona_data(url1, url2, filename, save = ['Y', 'N']):\n",
    "#     '''\n",
    "#     No longer works as Github change the way html codes for the tables\n",
    "#     '''\n",
    "#     dfdly = pd.read_html(url1)[0]#[2:-2]\n",
    "#     dfdly = dfdly[dfdly.Name.str.contains(r'.csv', case = False)]\n",
    "#     try:\n",
    "#         fdf = pd.read_csv(filename, low_memory = False)\n",
    "#         current_files = fdf.source.unique()\n",
    "#     except:\n",
    "#         fdf = pd.DataFrame()\n",
    "#         current_files = []\n",
    "#     counter = 0\n",
    "#     for file in dfdly.Name.unique():\n",
    "#         if file not in current_files:\n",
    "#             counter += 1\n",
    "#             clear_output(wait=True)\n",
    "#             print('{} New Data Found {}'.format(counter, file)) \n",
    "#             df2 = pd.read_html(url2+file, index_col=0)[0]\n",
    "#             df2.loc[:,'source'] = file\n",
    "#             fdf = pd.concat([fdf, df2], 0, sort = False)     \n",
    "#         else:\n",
    "#             continue\n",
    "#     if counter == 0:\n",
    "#         print('No new updates found!!!')\n",
    "#     else:\n",
    "#         print('{} New updates found!!!'.format(counter))\n",
    "#     if save == 'Y':\n",
    "#         fdf.to_csv(filename, index = False)    \n",
    "#         print('SAVED')\n",
    "#     return fdf\n",
    "\n",
    "# ## archived_daily_case_updates \n",
    "# # url1 = 'https://github.com/CSSEGISandData/COVID-19/tree/master/archived_data/archived_daily_case_updates'\n",
    "# # url2 = 'https://github.com/CSSEGISandData/COVID-19/blob/master/archived_data/archived_daily_case_updates/'\n",
    "# # file1 = 'coronavirus_dly_arch.csv'\n",
    "# # covid_arc = corona_data(url1, url2, file1, 'Y')\n",
    "# ### csse_covid_19_daily_reports \n",
    "# url3 = 'https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports'\n",
    "# url4 = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "# file2 = 'coronavirus_dly.csv'\n",
    "# covid_new = corona_data(url3, url4, file2, 'Y')\n",
    "# ### csse_covid_19_daily_reports_us\n",
    "# url5 = 'https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports_us'\n",
    "# url6 = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_daily_reports_us/'\n",
    "# file3 = 'coronavirus_dly_us.csv'\n",
    "# covid_usa = corona_data(url5, url6, file3, 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coviddonwload(filename, url_, mnt_year, save = 'Y', output = ['Y', 'N']):\n",
    "    ''' \n",
    "    Function to download and update local version of covid data from Github into the desired file (filename) \n",
    "        - US DATA:\n",
    "        'https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports_us'\n",
    "        - WORLD DATA\n",
    "        'https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports'\n",
    "    \n",
    "    PARAMETERS:\n",
    "        filename = local file to store the data - csv\n",
    "        url_ = one of the above urls\n",
    "        mnt_year = string in format MM-YYYY\n",
    "        save = whether or not to save the local file - useful to access the data fast\n",
    "        output = whether of not to produce a df as output\n",
    "\n",
    "    USAGE:\n",
    "        df_covid_us = coviddonwload('covid_data_github.csv', url, '11-2021', save = 'Y', output = 'Y')\n",
    "    '''\n",
    "    # Contents of the local file\n",
    "    try:\n",
    "        fdf = pd.read_csv(filename, low_memory = False)\n",
    "        current_files = fdf.source.unique()\n",
    "    except:\n",
    "        fdf = pd.DataFrame()\n",
    "        current_files = []\n",
    "    covgitdata = requests.get(url_)\n",
    "    soup = BeautifulSoup(covgitdata.content, \"lxml\")\n",
    "    \n",
    "    spans = soup.find_all('span', attrs={'class':'css-truncate'})\n",
    "    \n",
    "    spanlist = []\n",
    "    for sp in spans:\n",
    "        try: \n",
    "            sp = str(sp.string)\n",
    "        except:\n",
    "            continue\n",
    "        if ('csv' in sp)&(mnt_year[-4:] in sp)&(sp.startswith(mnt_year[:2])):\n",
    "            spanlist.append(sp)\n",
    "    spanlist = [data for data in spanlist if data not in fdf.source.unique()]\n",
    "    if len(spanlist) == 0:\n",
    "        print('No updates found -- No new data added to existing file')\n",
    "        return \n",
    "    else:\n",
    "        print('{} New updates found!!!'.format(len(spanlist)))\n",
    "        for file in spanlist:\n",
    "            df1 = pd.read_html(url_+'/'+file, index_col=0)[0].reset_index(drop = True)\n",
    "            df1.loc[:,'source'] = file\n",
    "            fdf = pd.concat([fdf, df1], axis = 0)\n",
    "\n",
    "        if (save == 'Y'):\n",
    "            fdf.to_csv(filename, index = False)    \n",
    "            print('File {} updated'.format(filename))\n",
    "        if output =='Y':\n",
    "            return fdf\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlus = 'https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports_us'\n",
    "start_mont = 1\n",
    "end_mont = 1\n",
    "year = 2023\n",
    "[coviddonwload('Covid_data/covid_data_github.csv', urlus, dt, save = 'Y', output = 'N') for dt in ['0'+str(d)+'-'+str(year) if len(str(d))==1 else str(d)+'-str(year)' for d in range(start_mont, end_mont+1,1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'American Samoa', 'Arizona', 'Arkansas',\n",
       "       'California', 'Colorado', 'Connecticut', 'Delaware',\n",
       "       'Diamond Princess', 'District of Columbia', 'Florida', 'Georgia',\n",
       "       'Grand Princess', 'Guam', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
       "       'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
       "       'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
       "       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "       'New Jersey', 'New Mexico', 'New York', 'North Carolina',\n",
       "       'North Dakota', 'Northern Mariana Islands', 'Ohio', 'Oklahoma',\n",
       "       'Oregon', 'Pennsylvania', 'Puerto Rico', 'Rhode Island',\n",
       "       'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah',\n",
       "       'Vermont', 'Virgin Islands', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming', 'Recovered'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read local dataset\n",
    "covid_arc = pd.read_csv('Covid_data/covid_data_github.csv', low_memory = False)\n",
    "corv_us = covid_arc[covid_arc['Country_Region']=='US']\n",
    "corv_us['Province_State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Getting latitude and longitude from geocode for each state\n",
    "# from geopy.geocoders import Nominatim\n",
    "# geolocator = Nominatim(user_agent='myapplication')\n",
    "\n",
    "# st_dc={}\n",
    "\n",
    "# for state in corv_us['Province_State'].unique():\n",
    "#     st_location = geolocator.geocode(state)\n",
    "#     st_dc[state] = {'lat':st_location.latitude, 'lon':st_location.longitude}\n",
    "# st_df = pd.DataFrame(st_dc).T.reset_index().rename(columns = {'index':'Province_State'})\n",
    "# st_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>Case_Fatality_Ratio</th>\n",
       "      <th>UID</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>Testing_Rate</th>\n",
       "      <th>Hospitalization_Rate</th>\n",
       "      <th>source</th>\n",
       "      <th>People_Tested</th>\n",
       "      <th>Mortality_Rate</th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "      <td>846297</td>\n",
       "      <td>16143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.907486</td>\n",
       "      <td>84000001.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>128306.702684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>US</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>61.3707</td>\n",
       "      <td>-152.4044</td>\n",
       "      <td>151323</td>\n",
       "      <td>881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582198</td>\n",
       "      <td>84000002.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>482687.326139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>US</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>-14.2710</td>\n",
       "      <td>-170.1320</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>ASM</td>\n",
       "      <td>3846.084722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>33.7298</td>\n",
       "      <td>-111.4312</td>\n",
       "      <td>1272943</td>\n",
       "      <td>22350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755774</td>\n",
       "      <td>84000004.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>200594.321774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>US</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>34.9697</td>\n",
       "      <td>-92.3731</td>\n",
       "      <td>529768</td>\n",
       "      <td>8687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.639774</td>\n",
       "      <td>84000005.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>140262.058106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province_State Country_Region          Last_Update      Lat     Long_  \\\n",
       "0         Alabama             US  2021-12-02 04:33:13  32.3182  -86.9023   \n",
       "1          Alaska             US  2021-12-02 04:33:13  61.3707 -152.4044   \n",
       "2  American Samoa             US  2021-12-02 04:33:13 -14.2710 -170.1320   \n",
       "3         Arizona             US  2021-12-02 04:33:13  33.7298 -111.4312   \n",
       "4        Arkansas             US  2021-12-02 04:33:13  34.9697  -92.3731   \n",
       "\n",
       "   Confirmed  Deaths  Recovered  Active  FIPS  ...  Case_Fatality_Ratio  \\\n",
       "0     846297   16143        NaN     NaN   1.0  ...             1.907486   \n",
       "1     151323     881        NaN     NaN   2.0  ...             0.582198   \n",
       "2          4       0        NaN     NaN  60.0  ...             0.000000   \n",
       "3    1272943   22350        NaN     NaN   4.0  ...             1.755774   \n",
       "4     529768    8687        NaN     NaN   5.0  ...             1.639774   \n",
       "\n",
       "          UID  ISO3   Testing_Rate  Hospitalization_Rate          source  \\\n",
       "0  84000001.0   USA  128306.702684                   NaN  12-01-2021.csv   \n",
       "1  84000002.0   USA  482687.326139                   NaN  12-01-2021.csv   \n",
       "2        16.0   ASM    3846.084722                   NaN  12-01-2021.csv   \n",
       "3  84000004.0   USA  200594.321774                   NaN  12-01-2021.csv   \n",
       "4  84000005.0   USA  140262.058106                   NaN  12-01-2021.csv   \n",
       "\n",
       "   People_Tested  Mortality_Rate Date  State  \n",
       "0            NaN             NaN  NaN     AL  \n",
       "1            NaN             NaN  NaN     AK  \n",
       "2            NaN             NaN  NaN     AS  \n",
       "3            NaN             NaN  NaN     AZ  \n",
       "4            NaN             NaN  NaN     AR  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_state_abbrev = {'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ','Arkansas': 'AR', 'California': 'CA', \n",
    "                    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL','Georgia': 'GA',\n",
    "                    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n",
    "                    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "                    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO',\n",
    "                    'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',\n",
    "                    'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Northern Mariana Islands': 'MP', 'Ohio': 'OH',\n",
    "                    'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "                    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT',\n",
    "                    'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY' ,          \n",
    "                    'District of Columbia': 'DC',\n",
    "                    'American Samoa': 'AS', 'Guam': 'GU', 'Puerto Rico': 'PR', 'Virgin Islands': 'VI',\n",
    "                    }\n",
    "state_field = 'Province_State'\n",
    "corv_us['State'] = np.where(corv_us[state_field].str.contains('|'.join(us_state_abbrev.values())), corv_us[state_field].str.extract(r\"\\,\\s([A-Z]{2})\", expand=False)\n",
    "                , np.where(corv_us[state_field].str.contains(r'Washington, D.C.', case = False), 'DC'\n",
    "                    , np.where(corv_us[state_field].str.contains(r'Chicago', case = False), 'IL', corv_us[state_field].map(us_state_abbrev)\n",
    "                        )))\n",
    "corv_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>State_nm</th>\n",
       "      <th>Last_updt</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Hospitalizations</th>\n",
       "      <th>Source</th>\n",
       "      <th>State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>846297</td>\n",
       "      <td>16143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>AL</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "      <td>12-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>151323</td>\n",
       "      <td>881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>AK</td>\n",
       "      <td>61.3707</td>\n",
       "      <td>-152.4044</td>\n",
       "      <td>12-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>1272943</td>\n",
       "      <td>22350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>AZ</td>\n",
       "      <td>33.7298</td>\n",
       "      <td>-111.4312</td>\n",
       "      <td>12-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2021-12-02 04:33:13</td>\n",
       "      <td>529768</td>\n",
       "      <td>8687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>AR</td>\n",
       "      <td>34.9697</td>\n",
       "      <td>-92.3731</td>\n",
       "      <td>12-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>California</td>\n",
       "      <td>2021-12-02 06:32:33</td>\n",
       "      <td>5088361</td>\n",
       "      <td>74528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12-01-2021.csv</td>\n",
       "      <td>CA</td>\n",
       "      <td>36.1162</td>\n",
       "      <td>-119.6816</td>\n",
       "      <td>12-01-2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country    State_nm            Last_updt  Confirmed  Deaths  Recovered  \\\n",
       "0      US     Alabama  2021-12-02 04:33:13     846297   16143        NaN   \n",
       "1      US      Alaska  2021-12-02 04:33:13     151323     881        NaN   \n",
       "3      US     Arizona  2021-12-02 04:33:13    1272943   22350        NaN   \n",
       "4      US    Arkansas  2021-12-02 04:33:13     529768    8687        NaN   \n",
       "5      US  California  2021-12-02 06:32:33    5088361   74528        NaN   \n",
       "\n",
       "   Hospitalizations          Source State      Lat       Lon        date  \n",
       "0               NaN  12-01-2021.csv    AL  32.3182  -86.9023  12-01-2021  \n",
       "1               NaN  12-01-2021.csv    AK  61.3707 -152.4044  12-01-2021  \n",
       "3               NaN  12-01-2021.csv    AZ  33.7298 -111.4312  12-01-2021  \n",
       "4               NaN  12-01-2021.csv    AR  34.9697  -92.3731  12-01-2021  \n",
       "5               NaN  12-01-2021.csv    CA  36.1162 -119.6816  12-01-2021  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corv_us2 = corv_us[['Country_Region', 'Province_State', 'Last_Update', 'Confirmed','Deaths', 'Recovered', 'People_Hospitalized','source', 'State', 'Lat', 'Long_']]\n",
    "corv_us2.columns = ['Country', 'State_nm', 'Last_updt', 'Confirmed', 'Deaths', 'Recovered', 'Hospitalizations', 'Source', 'State', 'Lat', 'Lon']\n",
    "corv_us2 = corv_us2[corv_us2.State.isin([\n",
    "        'SC', 'LA', 'VA', 'ID', 'IA', 'KY', 'MO', 'OK', 'CO', 'IL', 'IN',\n",
    "        'MS', 'NE', 'OH', 'PA', 'WA', 'WI', 'VT', 'MN', 'FL', 'NC', 'CA',\n",
    "        'NY', 'WY', 'MI', 'MD', 'AK', 'KS', 'TN', 'TX', 'ME', 'AZ', 'GA',\n",
    "        'AR', 'NJ', 'SD', 'AL', 'WV', 'ND', 'MA', 'UT', 'MT', 'NH', 'OR',\n",
    "        'NM', 'RI', 'NV', 'DC', 'CT', 'HI', 'DE'])]\n",
    "corv_us2.loc[:,'date']= corv_us2.Source.str.extract(r'([0-9]{2}-[0-9]{2}-[0-9]{4})', expand=False)\n",
    "corv_us2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_date_file = max([datetime.strptime(re.findall(r'^\\d+-\\d+-\\d+', x)[0], '%m-%d-%Y') for x in corv_us2.Source.unique()]).strftime(\"%m-%d-%Y\")+'.csv'\n",
    "\n",
    "corv_us_last = corv_us2[corv_us2.Source == max_date_file].reset_index(drop = True)\n",
    "corv_us_last.head()\n",
    "\n",
    "c_state = corv_us_last.groupby('State').Confirmed.sum()\\\n",
    "                                    .to_frame().merge(corv_us_last.groupby('State').Lat.mean(), left_index=True, right_index=True)\\\n",
    "                                    .merge(corv_us_last.groupby('State').Lon.mean(), left_index=True, right_index=True)\\\n",
    "                                    .merge(corv_us_last.groupby('State').State_nm.first(), left_index=True, right_index=True).reset_index(drop = False)\n",
    "c_state.to_csv('Covid_data/coronavirus_latest_data.csv', index = False)\n",
    "\n",
    "c_state.rename(columns = {'Lat':'Latitude',\t'Lon':'Longitude'}, inplace = True)\n",
    "# Setting the size of the circle based on the number of cases\n",
    "c_state.loc[:,'scale'] = c_state.Confirmed/max(c_state.Confirmed)\n",
    "min_size = c_state[c_state.scale >= 0.08].scale.min()\n",
    "max_size = c_state[c_state.scale >= 0.08].scale.max()\n",
    "\n",
    "c_state.loc[:,'size'] = np.where(c_state.Confirmed/max(c_state.Confirmed)==1, 100/2,\n",
    "                            np.where(c_state.Confirmed/max(c_state.Confirmed)>0.08, c_state.Confirmed/max(c_state.Confirmed)*100/2, min_size*100/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "\n",
    "# states = gpd.read_file('geopandas-tutorial/data/usa-states-census-2014.shp')\n",
    "# states.head()\n",
    "# # “EPSG:4326” WGS84 Latitude/Longitude, used in GPS\n",
    "# # “EPSG:3395” Spherical Mercator. Google Maps, OpenStreetMap, Bing Maps\n",
    "# # “EPSG:32633” UTM Zones (North) – (Universal Transverse Mercator)\n",
    "# # “EPSG:32733” UTM Zones (South) – (Universal Transverse Mercator)\n",
    "# states.crs\n",
    "# states = states.to_crs(\"EPSG:3395\")\n",
    "# states.crs\n",
    "#states.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Geographical data\n",
    "gdf = gpd.read_file('Covid_data/ne_110m_admin_0_countries.shp')[['ADMIN','ADM0_A3','geometry']]\n",
    "gdf.columns = ['country', 'country_code', 'geometry']\n",
    "gdf = gdf[gdf['country_code'] == 'USA']\n",
    "# print(gdf)\n",
    "# print('####', gdf.shape)\n",
    "#Read data to json.\n",
    "gdf_json = json.loads(gdf.to_json())\n",
    "# Convert to String like object.\n",
    "mgrid = json.dumps(gdf_json)\n",
    "grid_crs=gdf.crs\n",
    "# print(grid_crs)\n",
    "\n",
    "def map_plot1(dataf, lat, lng, grid_, key,  zoom=3, map_type='roadmap'):\n",
    "    \n",
    "    gmap_options = GMapOptions(lat=lat, lng=lng, \n",
    "                               map_type=map_type, zoom=zoom)\n",
    "    p = gmap(key, gmap_options, title='COVID-19 Cases in the USA by State', \n",
    "             width=600, height=400)\n",
    "    \n",
    "    geosourc = GeoJSONDataSource(geojson = grid_)\n",
    "    pointsourc = ColumnDataSource(dataf)\n",
    "\n",
    "    tile_provider = get_provider(CARTODBPOSITRON)\n",
    "\n",
    "    #Add patch renderer to figure. \n",
    "#     p.patches('xs','ys', source = geosourc,fill_color = 'lightgrey',\n",
    "#               line_color = 'black', line_width = 0.25, fill_alpha = 0.5)\n",
    "    f1 = p.circle('Longitude', 'Latitude',source=pointsourc, size='size', fill_alpha = 0.5)\n",
    "    \n",
    "    p.add_tools(HoverTool(renderers = [f1],\n",
    "    tooltips=[ ('', '@State_nm'), ('', '@Confirmed{0,0}'),\n",
    "             ]))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scattered plots and Layout\n",
    "data = corv_us2.groupby(['State', 'date']).Confirmed.sum().reset_index().rename(columns = {'State':'state_nm', 'Confirmed':'cases'})\n",
    "data.loc[:,'date'] = data.date.astype(np.datetime64)\n",
    "\n",
    "# Select States\n",
    "available_states = list(set(data['state_nm']))\n",
    "available_states.sort()\n",
    "# DataFrame with all the information\n",
    "alldf = ColumnDataSource(data)\n",
    "# Empty source so the plot is empty before data is selected and this will be the data shown in the plot\n",
    "current_1 = ColumnDataSource(dict(data[data.state_nm =='TX']))\n",
    "current_2 = ColumnDataSource(dict(date = [], cases = [], state_nm =[]))\n",
    "\n",
    "# view_1 = CDSView(source=current_1, filters=[IndexFilter([i for i in range(data.shape[0]-10, data.shape[0], 1)])])\n",
    "\n",
    "hover_tool = HoverTool(tooltips = [('State', '@state_nm'),\n",
    "                                   ('Date',  '@date{%Y-%m-%d}'),\n",
    "                                   ('Cases', '@cases{0,0}'),\n",
    "                                  ],\n",
    "                       formatters = {'@date': 'datetime'})\n",
    "\n",
    "def make_my_plot(alldfs, width, heigth, tools):\n",
    "    # view = CDSView(source=alldfs, filters=[IndexFilter([i for i in range(len(alldfs.data['state_nm'])-10, len(alldfs.data['state_nm']), 1)])])\n",
    "    plot = figure(width = width, height = heigth,  tools = tools)#, x_range = [(alldfs.data['date'].max() - timedelta(days=x)).strftime('%Y-%m-%d') for x in range(10)])# = alldf['date'].max())\n",
    "    plot.scatter(x = 'date', y = 'cases', source = alldfs\n",
    "                # , view = view\n",
    "                )#  color = 'state_color', line_width=2)\n",
    "    plot.yaxis.formatter=NumeralTickFormatter(format=\"0,0\")\n",
    "    plot.yaxis.axis_label = 'Cases (#)'\n",
    "    plot.xaxis.formatter=DatetimeTickFormatter(days=\"%b %d\")\n",
    "    plot.xaxis.major_label_orientation = pi/4\n",
    "    plot.xaxis.axis_label = 'Date'\n",
    "    plot.add_layout(Title(text = 'Cumulative Coronavirus Cases in the USA by State(s)',\n",
    "                            text_font_size = '12pt', text_font_style = 'italic'), 'above')\n",
    "\n",
    "    return plot\n",
    "\n",
    "def call_back_fun(all_data, current_1):\n",
    "    callb = CustomJS(args = dict(source=all_data, sc=current_1),\n",
    "                       code = '''\n",
    "                            var selected_state_nm   = cb_obj.value;\n",
    "                            sc.data['cases'] = [];\n",
    "                            sc.data['date'] = [];\n",
    "                            sc.data['state_nm']= [];\n",
    "                            for (let i = 0; i < source.data['cases'].length; i++) {\n",
    "                              if (selected_state_nm.indexOf(source.data['state_nm'][i]) >= 0) {\n",
    "                                sc.data['cases'][i] = source.data['cases'][i];\n",
    "                                sc.data['date'][i]  = source.data['date'][i];\n",
    "                                sc.data['state_nm'][i] = source.data['state_nm'][i];\n",
    "                                }\n",
    "                              }\n",
    "                              console.log(sc.data);\n",
    "                            sc.change.emit();\n",
    "                            '''\n",
    "                    )\n",
    "    return callb\n",
    "    \n",
    "def multi_select(all_data, current_data, select_tittle, size):\n",
    "    multiselect = MultiSelect(title = select_tittle, value = [], options = available_states, width = 150, size = size)\n",
    "    multiselect.js_on_change('value', call_back_fun(all_data, current_data))\n",
    "    return multiselect\n",
    "\n",
    "width = 500 \n",
    "height = 300\n",
    "Select_tittle = 'Select state(s)'\n",
    "tools = [hover_tool, 'box_zoom, pan, reset']\n",
    "size_selector = 15\n",
    "plot1 = make_my_plot(current_1, width, height, tools)\n",
    "\n",
    "lat, lon = 45, -115\n",
    "cases_map1 = map_plot1(c_state, lat, lon, mgrid, keys.goggle_gmaps_api)\n",
    "\n",
    "\n",
    "page_layout1 = column(row(multi_select(alldf, current_1, Select_tittle, size_selector), plot1), cases_map1)\n",
    "show(grid([page_layout1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11992d99215f2f7e82da41465ea0a5e3426276d538e4da9c1b068818cf2f1beb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
